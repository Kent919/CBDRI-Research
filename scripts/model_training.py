"""
model_training.py - è®­ç»ƒ CBDRI æ¨¡å‹ï¼ˆXGBoost-HMM + è´å¶æ–¯æ›´æ–°ï¼‰
"""
import os
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import joblib

PROCESSED_DIR = "data/processed"
MODELS_DIR = "models"
os.makedirs(MODELS_DIR, exist_ok=True)

def simulate_audit_labels(df):
    """æ¨¡æ‹Ÿäº‹åå®¡è®¡æ ‡ç­¾ï¼ˆç”¨äºè®­ç»ƒï¼‰"""
    np.random.seed(42)
    risk_score = (
        (df["ch_len"] > 300).astype(int) * 0.3 +
        (df["call_freq_in_5min"] > 5).astype(int) * 0.4 +
        np.random.rand(len(df)) * 0.3
    )
    labels = (risk_score > 0.7).astype(int)
    return labels

def train_likelihood_model():
    """è®­ç»ƒä¼¼ç„¶å‡½æ•° P(e_t | R_t)"""
    print("ğŸ§  è®­ç»ƒä¼¼ç„¶å‡½æ•°ï¼ˆé€»è¾‘å›å½’ï¼‰...")
    
    # åˆå¹¶æ•°æ®ï¼ˆæ¨¡æ‹Ÿ joinï¼‰
    tls_df = pd.read_csv(os.path.join(PROCESSED_DIR, "tls_meta_preprocessed.csv"))
    call_df = pd.read_csv(os.path.join(PROCESSED_DIR, "container_call_preprocessed.csv"))
    
    # æˆªæ–­é•¿åº¦å¯¹é½
    min_len = min(len(tls_df), len(call_df))
    tls_df = tls_df.iloc[:min_len].reset_index(drop=True)
    call_df = call_df.iloc[:min_len].reset_index(drop=True)
    
    X = pd.DataFrame({
        "ch_len": tls_df["ch_len"],
        "call_freq": call_df["call_freq_in_5min"],
        "sensitivity": call_df["data_type"].map({"ä½ç½®": 3, "ä¹˜å®¢æ•°": 2, "é€Ÿåº¦": 1})
    })
    
    y = simulate_audit_labels(X)  # æ¨¡æ‹Ÿå¤–æ³„æ ‡ç­¾
    
    model = LogisticRegression()
    model.fit(X, y)
    
    # ä¿å­˜æ¨¡å‹
    joblib.dump(model, os.path.join(MODELS_DIR, "likelihood_model.pkl"))
    print("âœ… ä¼¼ç„¶æ¨¡å‹å·²ä¿å­˜")
    
    # è¾“å‡ºç³»æ•°ï¼ˆå¯¹åº”è®ºæ–‡è¡¨)
    coeffs = [model.intercept_[0]] + model.coef_[0].tolist()
    print("ğŸ“Š ä¼¼ç„¶å‡½æ•°ç³»æ•°:")
    print(f"Î²0 (æˆªè·): {coeffs[0]:.2f}")
    print(f"Î²1 (ch_len): {coeffs[1]:.2f}")
    print(f"Î²2 (call_freq): {coeffs[2]:.2f}")
    print(f"Î²3 (sensitivity): {coeffs[3]:.2f}")

def bayesian_update_demo():
    """æ¼”ç¤ºè´å¶æ–¯åœ¨çº¿æ›´æ–°è¿‡ç¨‹"""
    print("ğŸ” æ¼”ç¤ºè´å¶æ–¯æ›´æ–°...")
    model_path = os.path.join(MODELS_DIR, "likelihood_model.pkl")
    if not os.path.exists(model_path):
        print("âš ï¸ è¯·å…ˆè¿è¡Œ model_training.py")
        return
    
    model = joblib.load(model_path)
    P_Rt = 0.1  # åˆå§‹å…ˆéªŒ
    
    # æ¨¡æ‹Ÿ5ä¸ªæ—¶é—´çª—å£
    examples = [
        {"ch_len": 320, "call_freq": 6, "sensitivity": 3},
        {"ch_len": 290, "call_freq": 4, "sensitivity": 2},
        {"ch_len": 350, "call_freq": 8, "sensitivity": 3},
        {"ch_len": 310, "call_freq": 5, "sensitivity": 3},
        {"ch_len": 280, "call_freq": 3, "sensitivity": 1},
    ]
    
    print("æ—¶é—´çª—å£\té£é™©æ¦‚ç‡")
    for i, e in enumerate(examples):
        log_odds = model.intercept_[0] + sum(c * v for c, v in zip(model.coef_[0], e.values()))
        likelihood_ratio = np.exp(log_odds)
        P_Rt = likelihood_ratio * P_Rt / (likelihood_ratio * P_Rt + (1 - P_Rt))
        print(f"T{i+1}\t\t{P_Rt:.3f}")
    
    print(f"âœ… æœ€ç»ˆé£é™©æ¦‚ç‡: {P_Rt:.3f}")

if __name__ == "__main__":
    train_likelihood_model()
    bayesian_update_demo()