"""
data_preprocessing.py - æ•°æ®æ¸…æ´—ä¸æ ‡å‡†åŒ–
"""
import os
import pandas as pd
from sklearn.preprocessing import StandardScaler
from datetime import datetime

PROCESSED_DIR = "data/processed"
OUTPUT_SUFFIX = "_preprocessed.csv"

def load_and_clean():
    """åŠ è½½å¹¶é¢„å¤„ç†ä¸‰å¼ è¡¨"""
    files = {
        "tls_meta": os.path.join(PROCESSED_DIR, "tls_meta.csv"),
        "container_call": os.path.join(PROCESSED_DIR, "container_call.csv"),
        "icc_lookup": os.path.join(PROCESSED_DIR, "icc_lookup.csv")
    }
    
    dfs = {}
    for name, path in files.items():
        print(f"ğŸ§¹ åŠ è½½å¹¶æ¸…æ´— {name}...")
        df = pd.read_csv(path)
        
        # å¼‚å¸¸å€¼è¿‡æ»¤
        if name == "tls_meta":
            df = df[(df["ch_len"] > 100) & (df["ch_len"] < 1500)]
            cols = ["ch_len", "cipher_suites", "up_packet_count", "down_packet_count", "avg_inter_arrival"]
            scaler = StandardScaler()
            df[cols] = scaler.fit_transform(df[cols])
        
        elif name == "container_call":
            df["timestamp"] = pd.to_datetime(df["timestamp"])
            df = df.dropna(subset=["timestamp"])
            df = df[df["call_freq_in_5min"] >= 1]
        
        # ä¿å­˜
        output_path = os.path.join(PROCESSED_DIR, name + OUTPUT_SUFFIX)
        df.to_csv(output_path, index=False)
        dfs[name] = df
        print(f"âœ… ä¿å­˜é¢„å¤„ç†åæ•°æ® â†’ {output_path}")
    
    return dfs

if __name__ == "__main__":
    processed_dfs = load_and_clean()
    print("ğŸ‰ æ•°æ®é¢„å¤„ç†å®Œæˆï¼")